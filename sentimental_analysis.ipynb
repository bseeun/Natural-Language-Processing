{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport plotly.graph_objs as go\nimport plotly.colors as colors","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:20:33.434022Z","iopub.execute_input":"2024-06-17T05:20:33.434632Z","iopub.status.idle":"2024-06-17T05:20:48.627523Z","shell.execute_reply.started":"2024-06-17T05:20:33.434606Z","shell.execute_reply":"2024-06-17T05:20:48.626719Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-17 05:20:37.917785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-17 05:20:37.917915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-17 05:20:38.086033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.layers import SimpleRNN, LSTM, Bidirectional, GRU\nfrom keras.layers import Input, MultiHeadAttention, Attention, AdditiveAttention\n\nfrom keras.layers import Embedding, Dense, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:45:57.817938Z","iopub.execute_input":"2024-06-17T05:45:57.818584Z","iopub.status.idle":"2024-06-17T05:45:57.824969Z","shell.execute_reply.started":"2024-06-17T05:45:57.818551Z","shell.execute_reply":"2024-06-17T05:45:57.824046Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data load","metadata":{}},{"cell_type":"code","source":"fields = ['text', 'sentiment']\ncsv_train = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/train.csv', \n                        encoding='ISO-8859-1',\n#                       on_bad_lines='skip',\n                        usecols=fields)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-17T05:46:00.430836Z","iopub.execute_input":"2024-06-17T05:46:00.431859Z","iopub.status.idle":"2024-06-17T05:46:00.598461Z","shell.execute_reply.started":"2024-06-17T05:46:00.431827Z","shell.execute_reply":"2024-06-17T05:46:00.597658Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"csv_train.tail(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:09.346077Z","iopub.execute_input":"2024-06-17T05:46:09.346435Z","iopub.status.idle":"2024-06-17T05:46:09.366513Z","shell.execute_reply.started":"2024-06-17T05:46:09.346407Z","shell.execute_reply":"2024-06-17T05:46:09.365631Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment\n27471  i`m defying gravity. and nobody in alll of oz,...   neutral\n27472  http://twitpic.com/663vr - Wanted to visit the...  negative\n27473   in spoke to you yesterday and u didnt respond...   neutral\n27474  So I get up early and I feel good about the da...  positive\n27475                                     enjoy ur night  positive\n27476   wish we could come see u on Denver  husband l...  negative\n27477   I`ve wondered about rake to.  The client has ...  negative\n27478   Yay good for both of you. Enjoy the break - y...  positive\n27479                         But it was worth it  ****.  positive\n27480     All this flirting going on - The ATG smiles...   neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27471</th>\n      <td>i`m defying gravity. and nobody in alll of oz,...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>27472</th>\n      <td>http://twitpic.com/663vr - Wanted to visit the...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27473</th>\n      <td>in spoke to you yesterday and u didnt respond...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>27474</th>\n      <td>So I get up early and I feel good about the da...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27475</th>\n      <td>enjoy ur night</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(csv_train.shape)\nprint(csv_train.isnull().sum())\nprint(csv_train.info)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:12.214818Z","iopub.execute_input":"2024-06-17T05:46:12.215170Z","iopub.status.idle":"2024-06-17T05:46:12.231476Z","shell.execute_reply.started":"2024-06-17T05:46:12.215142Z","shell.execute_reply":"2024-06-17T05:46:12.230534Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(27481, 2)\ntext         1\nsentiment    0\ndtype: int64\n<bound method DataFrame.info of                                                     text sentiment\n0                    I`d have responded, if I were going   neutral\n1          Sooo SAD I will miss you here in San Diego!!!  negative\n2                              my boss is bullying me...  negative\n3                         what interview! leave me alone  negative\n4       Sons of ****, why couldn`t they put them on t...  negative\n...                                                  ...       ...\n27476   wish we could come see u on Denver  husband l...  negative\n27477   I`ve wondered about rake to.  The client has ...  negative\n27478   Yay good for both of you. Enjoy the break - y...  positive\n27479                         But it was worth it  ****.  positive\n27480     All this flirting going on - The ATG smiles...   neutral\n\n[27481 rows x 2 columns]>\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_train.dropna(subset=[\"text\"], inplace=True)\nprint(csv_train.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:13.947434Z","iopub.execute_input":"2024-06-17T05:46:13.947896Z","iopub.status.idle":"2024-06-17T05:46:13.969810Z","shell.execute_reply.started":"2024-06-17T05:46:13.947865Z","shell.execute_reply":"2024-06-17T05:46:13.968896Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"text         0\nsentiment    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"def text_clean(text):\n    pattern1 = r'(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n    pattern2 = r'<[^>]*>'         # HTML 태그 제거\n    pattern3 = r'[^\\w\\s]'         # 특수기호제거\n    pattern = f'{pattern1}|{pattern2}|{pattern3}'\n    text = re.sub(pattern, '', text)\n    text = text.lower()\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:16.859301Z","iopub.execute_input":"2024-06-17T05:46:16.859980Z","iopub.status.idle":"2024-06-17T05:46:16.864872Z","shell.execute_reply.started":"2024-06-17T05:46:16.859946Z","shell.execute_reply":"2024-06-17T05:46:16.863916Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"csv_train['text'] = csv_train['text'].apply(text_clean)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:19.292787Z","iopub.execute_input":"2024-06-17T05:46:19.293121Z","iopub.status.idle":"2024-06-17T05:46:19.558739Z","shell.execute_reply.started":"2024-06-17T05:46:19.293095Z","shell.execute_reply":"2024-06-17T05:46:19.557803Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 'sentiment' 값을 숫자로 매핑하는 함수\nsentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}\ncsv_train['sentiment'] = csv_train['sentiment'].map(sentiment_map)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:20.365012Z","iopub.execute_input":"2024-06-17T05:46:20.365443Z","iopub.status.idle":"2024-06-17T05:46:20.374153Z","shell.execute_reply.started":"2024-06-17T05:46:20.365409Z","shell.execute_reply":"2024-06-17T05:46:20.373186Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"csv_train.tail(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:21.322894Z","iopub.execute_input":"2024-06-17T05:46:21.323235Z","iopub.status.idle":"2024-06-17T05:46:21.332081Z","shell.execute_reply.started":"2024-06-17T05:46:21.323207Z","shell.execute_reply":"2024-06-17T05:46:21.331177Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                    text  sentiment\n27476   wish we could come see u on denver  husband l...          0\n27477   ive wondered about rake to  the client has ma...          0\n27478   yay good for both of you enjoy the break  you...          2\n27479                              but it was worth it            2\n27480     all this flirting going on  the atg smiles ...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27476</th>\n      <td>wish we could come see u on denver  husband l...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>ive wondered about rake to  the client has ma...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>yay good for both of you enjoy the break  you...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>but it was worth it</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>all this flirting going on  the atg smiles ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('Train data shape: ', csv_train.shape)\nn_lebel = len(csv_train[csv_train.sentiment == 0])\nprint('negative in Train data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(csv_train)))\nn_lebel = len(csv_train[csv_train.sentiment == 1])\nprint('neutral in Train data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(csv_train)))\nn_lebel = len(csv_train[csv_train.sentiment == 2])\nprint('positive in Train data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(csv_train)))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:23.346166Z","iopub.execute_input":"2024-06-17T05:46:23.346533Z","iopub.status.idle":"2024-06-17T05:46:23.358292Z","shell.execute_reply.started":"2024-06-17T05:46:23.346502Z","shell.execute_reply":"2024-06-17T05:46:23.357357Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train data shape:  (27480, 2)\nnegative in Train data: 7781 (28.3%)\nneutral in Train data: 11117 (40.5%)\npositive in Train data: 8582 (31.2%)\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:24.361185Z","iopub.execute_input":"2024-06-17T05:46:24.362021Z","iopub.status.idle":"2024-06-17T05:46:37.447919Z","shell.execute_reply.started":"2024-06-17T05:46:24.361977Z","shell.execute_reply":"2024-06-17T05:46:37.446711Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, BertModel\nimport torch\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:40.750275Z","iopub.execute_input":"2024-06-17T05:46:40.751052Z","iopub.status.idle":"2024-06-17T05:46:44.654305Z","shell.execute_reply.started":"2024-06-17T05:46:40.751014Z","shell.execute_reply":"2024-06-17T05:46:44.653562Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:46.448821Z","iopub.execute_input":"2024-06-17T05:46:46.449725Z","iopub.status.idle":"2024-06-17T05:46:47.727532Z","shell.execute_reply.started":"2024-06-17T05:46:46.449687Z","shell.execute_reply":"2024-06-17T05:46:47.726780Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc2aabe89a741b985c1bdeb4fd556e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21163981302e45b7b4345aac2301b8d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"439e1d037bd240c5b48d196866dd604b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c52a98fec324792904527350a50a9d9"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_text(text):\n    tokens = tokenizer.encode_plus(text, \n                                   add_special_tokens=True,\n                                   max_length=128,\n                                   padding='max_length',\n                                   truncation=True,\n                                   return_token_type_ids=False,\n                                   return_attention_mask=True,\n                                   return_tensors='pt')\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:56.964826Z","iopub.execute_input":"2024-06-17T05:46:56.965797Z","iopub.status.idle":"2024-06-17T05:46:56.971091Z","shell.execute_reply.started":"2024-06-17T05:46:56.965736Z","shell.execute_reply":"2024-06-17T05:46:56.970146Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# 데이터셋 클래스 정의\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        tokenized_text = tokenize_text(text)\n        return {\n            'input_ids': tokenized_text['input_ids'].flatten(),\n            'attention_mask': tokenized_text['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:46:57.936857Z","iopub.execute_input":"2024-06-17T05:46:57.937496Z","iopub.status.idle":"2024-06-17T05:46:57.943979Z","shell.execute_reply.started":"2024-06-17T05:46:57.937467Z","shell.execute_reply":"2024-06-17T05:46:57.943041Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Train Data Set","metadata":{}},{"cell_type":"code","source":"# 데이터셋 분할\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(csv_train['text'].values, \n                                                                    csv_train['sentiment'].values, \n                                                                    test_size=0.2, \n                                                                    random_state=42)\n\n# 데이터로더 생성\ntrain_dataset = SentimentDataset(train_texts, train_labels)\nval_dataset = SentimentDataset(val_texts, val_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:47:01.060459Z","iopub.execute_input":"2024-06-17T05:47:01.061105Z","iopub.status.idle":"2024-06-17T05:47:01.074969Z","shell.execute_reply.started":"2024-06-17T05:47:01.061074Z","shell.execute_reply":"2024-06-17T05:47:01.073985Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# test데이터셋 만들기\nfields = ['text', 'sentiment']\ncsv_test = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/test.csv', \n                        encoding='ISO-8859-1',\n                        usecols=fields)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:47:02.247526Z","iopub.execute_input":"2024-06-17T05:47:02.247991Z","iopub.status.idle":"2024-06-17T05:47:02.414697Z","shell.execute_reply.started":"2024-06-17T05:47:02.247957Z","shell.execute_reply":"2024-06-17T05:47:02.413932Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Test Data Set","metadata":{}},{"cell_type":"code","source":"csv_test.dropna(subset=[\"text\"], inplace=True)\ncsv_test['text'] = csv_test['text'].apply(text_clean)\nprint(csv_test.isnull().sum())\nprint(csv_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:47:06.385051Z","iopub.execute_input":"2024-06-17T05:47:06.385949Z","iopub.status.idle":"2024-06-17T05:47:06.432213Z","shell.execute_reply.started":"2024-06-17T05:47:06.385918Z","shell.execute_reply":"2024-06-17T05:47:06.431337Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"text         0\nsentiment    0\ndtype: int64\n(3534, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:47:08.260738Z","iopub.execute_input":"2024-06-17T05:47:08.261406Z","iopub.status.idle":"2024-06-17T05:47:08.270991Z","shell.execute_reply.started":"2024-06-17T05:47:08.261375Z","shell.execute_reply":"2024-06-17T05:47:08.270030Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                text sentiment\n0                     last session of the day  67ezh   neutral\n1   shanghai is also really exciting precisely  s...  positive\n2  recession hit veronique branquinho she has to ...  negative\n3                                         happy bday  positive\n4                                   4w75p  i like it  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>last session of the day  67ezh</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>shanghai is also really exciting precisely  s...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>recession hit veronique branquinho she has to ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4w75p  i like it</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}\ncsv_test['sentiment'] = csv_test['sentiment'].map(sentiment_map)\n\ntest_texts = csv_test['text'].values\ntest_labels = csv_test['sentiment'].values\ntest_dataset = SentimentDataset(test_texts, test_labels)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:47:17.045805Z","iopub.execute_input":"2024-06-17T05:47:17.046401Z","iopub.status.idle":"2024-06-17T05:47:17.053623Z","shell.execute_reply.started":"2024-06-17T05:47:17.046367Z","shell.execute_reply":"2024-06-17T05:47:17.052694Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## BERT Model Train","metadata":{}},{"cell_type":"code","source":"# BERT 모델 로드\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n\n# 옵티마이저 및 손실 함수 정의\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# 모델 학습\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T05:53:40.946822Z","iopub.execute_input":"2024-06-15T05:53:40.947465Z","iopub.status.idle":"2024-06-15T05:53:44.603392Z","shell.execute_reply.started":"2024-06-15T05:53:40.947435Z","shell.execute_reply":"2024-06-15T05:53:44.602402Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f241e086784c899ff68ad885c57c5c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 5\nfor epoch in range(epochs):\n    model.train()\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n    \n    # 검증 데이터셋으로 평가\n    model.eval()\n    val_preds = []\n    val_true = []\n    for batch in val_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        with torch.no_grad():\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n        \n        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n        val_preds.extend(preds)\n        val_true.extend(labels.cpu().numpy())\n    \n    val_acc = accuracy_score(val_true, val_preds)\n    print(f'Epoch {epoch + 1}/{epochs}, Validation Accuracy: {val_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T05:53:44.604797Z","iopub.execute_input":"2024-06-15T05:53:44.605200Z","iopub.status.idle":"2024-06-15T06:34:44.617572Z","shell.execute_reply.started":"2024-06-15T05:53:44.605167Z","shell.execute_reply":"2024-06-15T06:34:44.616383Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/5, Validation Accuracy: 0.7786\nEpoch 2/5, Validation Accuracy: 0.7862\nEpoch 3/5, Validation Accuracy: 0.7809\nEpoch 4/5, Validation Accuracy: 0.7806\nEpoch 5/5, Validation Accuracy: 0.7769\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Test","metadata":{}},{"cell_type":"code","source":"model.eval()\ntest_preds = []\ntest_true = []\nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    labels = batch['labels'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n    \n    preds = torch.argmax(logits, dim=-1).cpu().numpy()\n    test_preds.extend(preds)\n    test_true.extend(labels.cpu().numpy())\n\ntest_acc = accuracy_score(test_true, test_preds)\nprint(f'Test Accuracy: {test_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T06:34:44.619657Z","iopub.execute_input":"2024-06-15T06:34:44.620115Z","iopub.status.idle":"2024-06-15T06:35:10.512523Z","shell.execute_reply.started":"2024-06-15T06:34:44.620058Z","shell.execute_reply":"2024-06-15T06:35:10.511624Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7651\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(test_true, test_preds, target_names=['negative', 'neutral', 'positive']))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T06:35:10.513676Z","iopub.execute_input":"2024-06-15T06:35:10.514038Z","iopub.status.idle":"2024-06-15T06:35:10.550701Z","shell.execute_reply.started":"2024-06-15T06:35:10.513989Z","shell.execute_reply":"2024-06-15T06:35:10.549673Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.73      0.82      0.77      1001\n     neutral       0.73      0.72      0.72      1430\n    positive       0.85      0.78      0.81      1103\n\n    accuracy                           0.77      3534\n   macro avg       0.77      0.77      0.77      3534\nweighted avg       0.77      0.77      0.77      3534\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### GPT Model Train","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import OpenAIGPTTokenizer, OpenAIGPTModel, AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:48:44.386139Z","iopub.execute_input":"2024-06-17T05:48:44.386819Z","iopub.status.idle":"2024-06-17T05:48:44.391601Z","shell.execute_reply.started":"2024-06-17T05:48:44.386788Z","shell.execute_reply":"2024-06-17T05:48:44.390871Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# 감정 분석 모델 정의\nclass SentimentClassifier(nn.Module):\n    def __init__(self, model_name, num_classes):\n        super(SentimentClassifier, self).__init__()\n        self.model = OpenAIGPTModel.from_pretrained(model_name)\n        self.tokenizer = OpenAIGPTTokenizer.from_pretrained(model_name)\n        self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n        self.tokenizer.padding_side = 'right'\n        self.model.resize_token_embeddings(len(self.tokenizer))\n        self.linear = nn.Linear(self.model.config.hidden_size, num_classes)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, input_ids, attention_mask=None):\n        outputs = self.model(input_ids, attention_mask=attention_mask)\n        logits = self.linear(outputs.last_hidden_state[:, -1, :])\n        return self.softmax(logits)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:48:45.342891Z","iopub.execute_input":"2024-06-17T05:48:45.343241Z","iopub.status.idle":"2024-06-17T05:48:45.350704Z","shell.execute_reply.started":"2024-06-17T05:48:45.343213Z","shell.execute_reply":"2024-06-17T05:48:45.349796Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 모델 인스턴스 생성\nnum_classes = 3\nmodel = SentimentClassifier(\"openai-gpt\", num_classes)\n\n# 옵티마이저 및 손실 함수 정의\noptimizer = AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# 모델 학습\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:48:50.480117Z","iopub.execute_input":"2024-06-17T05:48:50.480475Z","iopub.status.idle":"2024-06-17T05:48:55.090700Z","shell.execute_reply.started":"2024-06-17T05:48:50.480446Z","shell.execute_reply":"2024-06-17T05:48:55.089765Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e686951fc014608a76999e81ee7caf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505f6c5ab20a43f6b40091815b10b930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff19635d8ee41d8baf15083d2cb0041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff3e1098eb24483a9dd00e9e1c5de1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b4666cb4f354333ba7d051652883afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8511471484418fbc02061e9e571cd6"}},"metadata":{}},{"name":"stderr","text":"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"SentimentClassifier(\n  (model): OpenAIGPTModel(\n    (tokens_embed): Embedding(40479, 768)\n    (positions_embed): Embedding(512, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x Block(\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (linear): Linear(in_features=768, out_features=3, bias=True)\n  (softmax): Softmax(dim=-1)\n)"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 5\nfor epoch in range(epochs):\n    model.train()\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # 검증 데이터셋으로 평가\n    model.eval()\n    val_preds = []\n    val_true = []\n    for batch in val_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        with torch.no_grad():\n            outputs = model(input_ids, attention_mask=attention_mask)\n        \n        preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n        val_preds.extend(preds)\n        val_true.extend(labels.cpu().numpy())\n    \n    val_acc = accuracy_score(val_true, val_preds)\n    print(f'Epoch {epoch + 1}/{epochs}, Validation Accuracy: {val_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T05:49:52.975774Z","iopub.execute_input":"2024-06-17T05:49:52.976635Z","iopub.status.idle":"2024-06-17T06:35:00.706607Z","shell.execute_reply.started":"2024-06-17T05:49:52.976600Z","shell.execute_reply":"2024-06-17T06:35:00.705657Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/5, Validation Accuracy: 0.5890\nEpoch 2/5, Validation Accuracy: 0.6541\nEpoch 3/5, Validation Accuracy: 0.6743\nEpoch 4/5, Validation Accuracy: 0.6834\nEpoch 5/5, Validation Accuracy: 0.6827\n","output_type":"stream"}]},{"cell_type":"code","source":"# 테스트 데이터셋으로 평가\nmodel.eval()\ntest_preds = []\ntest_true = []\nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    labels = batch['labels'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n    \n    preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n    test_preds.extend(preds)\n    test_true.extend(labels.cpu().numpy())\n\ntest_acc = accuracy_score(test_true, test_preds)\nprint(f'Test Accuracy: {test_acc:.4f}')\nprint(classification_report(test_true, test_preds, target_names=['negative', 'neutral', 'positive']))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T06:35:33.153683Z","iopub.execute_input":"2024-06-17T06:35:33.154413Z","iopub.status.idle":"2024-06-17T06:36:00.498272Z","shell.execute_reply.started":"2024-06-17T06:35:33.154378Z","shell.execute_reply":"2024-06-17T06:36:00.497334Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.6822\n              precision    recall  f1-score   support\n\n    negative       0.69      0.61      0.64      1001\n     neutral       0.64      0.69      0.66      1430\n    positive       0.74      0.75      0.74      1103\n\n    accuracy                           0.68      3534\n   macro avg       0.69      0.68      0.68      3534\nweighted avg       0.68      0.68      0.68      3534\n\n","output_type":"stream"}]}]}